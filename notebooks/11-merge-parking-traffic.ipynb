{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# Merge Parking Occupancy and Traffic Data\n",
    "\n",
    "This notebook combines the cleaned historical traffic data with the \n",
    "parking occupancy data. It uses a mapping file to link parking zones\n",
    "to nearby traffic segments (ID_TRAM) and joins the datasets based on\n",
    "timestamp and location.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd # Optional: if using geospatial mapping\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# --- !!! REPLACE PARKING_DATA_FILE PLACEHOLDER !!! ---\n",
    "PARKING_DATA_FILE = \"../data/processed/parking_occupancy_processed.parquet\" # Example path - REPLACE\n",
    "PROCESSED_TRAMS_GPKG = \"../data/processed/trams_processed.gpkg\" # Use the processed TRAMS GeoPackage\n",
    "CLEANED_TRAFFIC_FILE = \"../data/cleaned/traffic_history_2022_2023_cleaned.parquet\"\n",
    "OUTPUT_DIR = \"../data/features\" # Save final feature set here\n",
    "OUTPUT_FILENAME = \"parking_traffic_merged_features.parquet\"\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_DIR, OUTPUT_FILENAME)\n",
    "\n",
    "# --- Column Names (Adjust as per your actual data) ---\n",
    "# Parking Data\n",
    "PARKING_TIMESTAMP_COL = 'Timestamp'\n",
    "PARKING_ZONE_ID_COL = 'ParkingZoneID' # IMPORTANT: Assuming this corresponds to ID_TRAM for now\n",
    "PARKING_TARGET_COL = 'OccupancyPercentage' # Your target variable\n",
    "\n",
    "# Traffic Data\n",
    "TRAFFIC_TIMESTAMP_COL = 'Timestamp'\n",
    "TRAFFIC_ID_COL = 'ID_TRAM'\n",
    "TRAFFIC_FEATURES = ['EstatActual', 'PrevisioActual']\n",
    "\n",
    "# TRAMS GeoPackage (assuming it contains ID_TRAM and other relevant static features)\n",
    "TRAMS_ID_COL = 'ID_TRAM' \n",
    "# Add other static features from trams_processed.gpkg you want to keep\n",
    "TRAMS_STATIC_FEATURES = ['TARIFA_TYPE', 'APPLIES_ON_HOLIDAYS', 'PARKING_ONLY_IN_SCHEDULE', 'PLACES'] \n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load Data ---\n",
    "print(\"Loading datasets...\")\n",
    "start_load_time = time.time()\n",
    "\n",
    "gdf_trams = None # Initialize\n",
    "df_parking = None\n",
    "df_traffic = None\n",
    "\n",
    "try:\n",
    "    df_traffic = pd.read_parquet(CLEANED_TRAFFIC_FILE)\n",
    "    # Keep only necessary columns and ensure timestamp type\n",
    "    df_traffic = df_traffic[[TRAFFIC_TIMESTAMP_COL, TRAFFIC_ID_COL] + TRAFFIC_FEATURES]\n",
    "    df_traffic[TRAFFIC_TIMESTAMP_COL] = pd.to_datetime(df_traffic[TRAFFIC_TIMESTAMP_COL])\n",
    "    print(f\"Loaded Traffic Data: {df_traffic.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Cleaned traffic file not found at {CLEANED_TRAFFIC_FILE}\")\n",
    "    # exit() \n",
    "\n",
    "try:\n",
    "    df_parking = pd.read_parquet(PARKING_DATA_FILE)\n",
    "    # Keep only necessary columns and ensure timestamp type\n",
    "    df_parking = df_parking[[PARKING_TIMESTAMP_COL, PARKING_ZONE_ID_COL, PARKING_TARGET_COL]]\n",
    "    df_parking[PARKING_TIMESTAMP_COL] = pd.to_datetime(df_parking[PARKING_TIMESTAMP_COL])\n",
    "    print(f\"Loaded Parking Data: {df_parking.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Parking data file not found at {PARKING_DATA_FILE}. Please update the path.\")\n",
    "    # exit() \n",
    "    \n",
    "try:\n",
    "    # Load the processed TRAMS GeoPackage\n",
    "    gdf_trams = gpd.read_file(PROCESSED_TRAMS_GPKG, layer='trams')\n",
    "    # Keep only necessary columns: ID and static features (+ geometry if needed later)\n",
    "    cols_to_keep = [TRAMS_ID_COL] + TRAMS_STATIC_FEATURES + ['geometry']\n",
    "    # Filter out columns not present in the GeoPackage\n",
    "    cols_to_keep = [col for col in cols_to_keep if col in gdf_trams.columns]\n",
    "    gdf_trams = gdf_trams[cols_to_keep]\n",
    "    print(f\"Loaded TRAMS GeoPackage: {gdf_trams.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to load TRAMS GeoPackage from {PROCESSED_TRAMS_GPKG}: {e}\")\n",
    "    # exit() \n",
    "\n",
    "end_load_time = time.time()\n",
    "print(f\"Data loading completed in {end_load_time - start_load_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Prepare Data for Merge ---\n",
    "# Proceed only if all dataframes loaded successfully\n",
    "if df_parking is not None and df_traffic is not None and gdf_trams is not None:\n",
    "    print(\"\\nPreparing data for merge...\")\n",
    "\n",
    "    # Ensure ID columns have compatible types for merging\n",
    "    try:\n",
    "        # Convert parking zone ID to the same type as TRAMS ID from GeoPackage\n",
    "        parking_id_dtype = gdf_trams[TRAMS_ID_COL].dtype\n",
    "        df_parking[PARKING_ZONE_ID_COL] = df_parking[PARKING_ZONE_ID_COL].astype(parking_id_dtype)\n",
    "        # Convert traffic ID to the same type\n",
    "        df_traffic[TRAFFIC_ID_COL] = df_traffic[TRAFFIC_ID_COL].astype(parking_id_dtype)\n",
    "        print(f\"Ensured {PARKING_ZONE_ID_COL}, {TRAFFIC_ID_COL}, and {TRAMS_ID_COL} have compatible type {parking_id_dtype}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not align ID column types - {e}. Merge might fail or be inefficient.\")\n",
    "\n",
    "    # --- 3. Perform Merge ---\n",
    "    # We will merge parking data with traffic data first, then add static TRAM features.\n",
    "    print(\"\\nPerforming merge operations...\")\n",
    "    start_merge_time = time.time()\n",
    "\n",
    "    # Step 3a: Merge parking data with traffic data\n",
    "    # Assuming PARKING_ZONE_ID_COL directly maps to TRAFFIC_ID_COL (ID_TRAM)\n",
    "    print(\"Merging parking data with traffic data...\")\n",
    "    df_merged = pd.merge(\n",
    "        df_parking,\n",
    "        df_traffic,\n",
    "        left_on=[PARKING_TIMESTAMP_COL, PARKING_ZONE_ID_COL], \n",
    "        right_on=[TRAFFIC_TIMESTAMP_COL, TRAFFIC_ID_COL],\n",
    "        how='left' # Keep all parking records, add traffic features where match found\n",
    "    )\n",
    "    print(f\"Shape after merging parking with traffic: {df_merged.shape}\")\n",
    "\n",
    "    # Check for missing traffic data after merge\n",
    "    missing_traffic_count = df_merged[TRAFFIC_FEATURES[0]].isnull().sum() # Check first traffic feature\n",
    "    print(f\"Rows with missing traffic data after merge: {missing_traffic_count}\")\n",
    "\n",
    "    # Clean up redundant columns from traffic merge\n",
    "    df_merged.drop(columns=[TRAFFIC_TIMESTAMP_COL, TRAFFIC_ID_COL], inplace=True, errors='ignore')\n",
    "\n",
    "    # Step 3b: Merge static TRAM features from GeoPackage\n",
    "    print(\"\\nMerging static TRAM features...\")\n",
    "    # Prepare gdf_trams for merge (drop geometry if not needed, keep only ID and static features)\n",
    "    trams_features_to_merge = gdf_trams[[TRAMS_ID_COL] + TRAMS_STATIC_FEATURES].copy()\n",
    "    # Ensure ID column type matches for this merge as well\n",
    "    trams_features_to_merge[TRAMS_ID_COL] = trams_features_to_merge[TRAMS_ID_COL].astype(df_merged[PARKING_ZONE_ID_COL].dtype)\n",
    "\n",
    "    df_merged = pd.merge(\n",
    "        df_merged,\n",
    "        trams_features_to_merge,\n",
    "        left_on=PARKING_ZONE_ID_COL, # Use the parking zone ID\n",
    "        right_on=TRAMS_ID_COL,       # Match with TRAM ID in GeoPackage features\n",
    "        how='left'                   # Keep all merged parking/traffic rows\n",
    "    )\n",
    "    print(f\"Shape after merging static TRAM features: {df_merged.shape}\")\n",
    "\n",
    "    # Check for missing static features after merge\n",
    "    # Check if TRAMS_STATIC_FEATURES exist before checking isnull()\n",
    "    cols_exist = [col for col in TRAMS_STATIC_FEATURES if col in df_merged.columns]\n",
    "    missing_static_count = df_merged[cols_exist].isnull().sum().sum() if cols_exist else 0\n",
    "    print(f\"Total missing static TRAM features after merge: {missing_static_count}\")\n",
    "\n",
    "    # Clean up redundant ID column from TRAMS merge\n",
    "    df_merged.drop(columns=[TRAMS_ID_COL], inplace=True, errors='ignore')\n",
    "\n",
    "    end_merge_time = time.time()\n",
    "    print(f\"Merge operations completed in {end_merge_time - start_merge_time:.2f} seconds.\")\n",
    "\n",
    "    # --- 4. Post-Merge Handling for Missing Features ---\\\n",
    "    print(\"\\n--- Post-Merge Handling ---\")\n",
    "\n",
    "    # Handle missing Traffic Features (EstatActual, PrevisioActual)\n",
    "    # These are likely missing due to the Oct 2023 gap or mismatches.\n",
    "    # Strategy: Fill with 0 (implies 'No Data' / 'Very Fluid' baseline)\n",
    "    print(f\"Filling {missing_traffic_count} instances of missing traffic features with 0...\")\n",
    "    df_merged[TRAFFIC_FEATURES] = df_merged[TRAFFIC_FEATURES].fillna(0).astype('Int8') # Ensure Int8 type\n",
    "\n",
    "    # Handle missing Static TRAM Features \n",
    "    # These would be missing if a PARKING_ZONE_ID_COL value didn't exist in trams_processed.gpkg\n",
    "    print(f\"Handling {missing_static_count} instances of missing static TRAM features...\")\n",
    "    if 'TARIFA_TYPE' in df_merged.columns:\n",
    "        df_merged['TARIFA_TYPE'].fillna('Unknown', inplace=True)\n",
    "    if 'APPLIES_ON_HOLIDAYS' in df_merged.columns:\n",
    "        # Fill NA then convert to bool\n",
    "        df_merged['APPLIES_ON_HOLIDAYS'] = df_merged['APPLIES_ON_HOLIDAYS'].fillna(False).astype(bool) \n",
    "    if 'PARKING_ONLY_IN_SCHEDULE' in df_merged.columns:\n",
    "        # Fill NA then convert to bool\n",
    "        df_merged['PARKING_ONLY_IN_SCHEDULE'] = df_merged['PARKING_ONLY_IN_SCHEDULE'].fillna(False).astype(bool)\n",
    "    if 'PLACES' in df_merged.columns:\n",
    "         # Calculate median *after* potential merge, on the non-NA values\n",
    "         places_median = df_merged['PLACES'].median()\n",
    "         df_merged['PLACES'].fillna(places_median, inplace=True) \n",
    "         df_merged['PLACES'] = df_merged['PLACES'].astype(int) # Convert to int after filling NAs\n",
    "\n",
    "    print(\"\\nFinal check for missing values:\")\n",
    "    print(df_merged.isnull().sum())\n",
    "\n",
    "    # --- 5. Save Merged Dataset ---\n",
    "    print(\"\\n--- Saving Final Merged Dataset ---\")\n",
    "    print(f\"Final dataset shape: {df_merged.shape}\")\n",
    "    print(f\"Saving to: {OUTPUT_FILE}\")\n",
    "\n",
    "    start_save_time = time.time()\n",
    "    try:                 \n",
    "        df_merged.to_parquet(OUTPUT_FILE, index=False, engine='pyarrow')\n",
    "        end_save_time = time.time()\n",
    "        print(f\"Merged data saved successfully in {end_save_time - start_save_time:.2f} seconds.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saving merged data: {e}\")\n",
    "\n",
    "    print(\"\\n--- Merging Process Complete ---\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- Merging Process Aborted: One or more input dataframes failed to load. ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
