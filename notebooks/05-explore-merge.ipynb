{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Exploration and Refinement of TRAMS.csv Data\n",
    "\n",
    "This notebook performs quality checks on TRAMS.csv, constructs geometries,\n",
    "and merges information from TARIFES.csv and HORARIS.csv.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString # To construct geometry\n",
    "from shapely.errors import GEOSException # For error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DATA_DIR = \"../data/raw\" # Adjust if your notebook structure is different\n",
    "TRAMS_FILE = os.path.join(DATA_DIR, \"TRAMS.csv\")\n",
    "TARIFES_FILE = os.path.join(DATA_DIR, \"TARIFES.csv\") # Need this again\n",
    "HORARIS_FILE = os.path.join(DATA_DIR, \"HORARIS.csv\") # Need this again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TRAMS data from: ../data/raw/TRAMS.csv\n",
      "TRAMS data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load TRAMS Data ---\n",
    "print(f\"Loading TRAMS data from: {TRAMS_FILE}\")\n",
    "try:\n",
    "    # Initial load - might need dtype specification if columns were mixed\n",
    "    df_trams_initial = pd.read_csv(TRAMS_FILE)\n",
    "    print(\"TRAMS data loaded successfully.\")\n",
    "    # Explicitly copy to avoid SettingWithCopyWarning later\n",
    "    df_trams = df_trams_initial.copy() \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {TRAMS_FILE}\")\n",
    "    df_trams = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Basic Info Recap ---\n",
      "Shape (Rows, Columns): (17275, 17)\n",
      "\n",
      "Columns and Data Types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17275 entries, 0 to 17274\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ID_TRAM      17275 non-null  int64  \n",
      " 1   UTM_IX       17275 non-null  float64\n",
      " 2   UTM_FX       17275 non-null  float64\n",
      " 3   UTM_IY       17275 non-null  float64\n",
      " 4   UTM_FY       17275 non-null  float64\n",
      " 5   LATITUD_I    17275 non-null  float64\n",
      " 6   LONGITUD_I   17275 non-null  float64\n",
      " 7   LATITUD_F    17275 non-null  float64\n",
      " 8   LONGITUD_F   17275 non-null  float64\n",
      " 9   ID_TARIFA    17275 non-null  int64  \n",
      " 10  ID_HORARIO   17275 non-null  int64  \n",
      " 11  ID_TARIFA1   11643 non-null  float64\n",
      " 12  ID_HORARIO1  17275 non-null  int64  \n",
      " 13  TIPUS_TRAM   17275 non-null  object \n",
      " 14  ADREÇA       17275 non-null  object \n",
      " 15  COLOR_RGB    17275 non-null  object \n",
      " 16  PLACES       17275 non-null  int64  \n",
      "dtypes: float64(9), int64(5), object(3)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# --- Basic Info Recap ---\n",
    "if not df_trams.empty:\n",
    "    print(\"--- Basic Info Recap ---\")\n",
    "    print(f\"Shape (Rows, Columns): {df_trams.shape}\")\n",
    "    print(\"\\nColumns and Data Types:\")\n",
    "    df_trams.info()\n",
    "else:\n",
    "    print(\"TRAMS DataFrame is empty. Stopping execution.\")\n",
    "    # If using in a script, you might exit here. In notebook, subsequent cells might fail.\n",
    "\n",
    "# === Data Quality Checks (Run these first if desired) ===\n",
    "# (You can uncomment and run these blocks from previous steps if needed)\n",
    "# print(\"\\n--- Running Data Quality Checks ---\")\n",
    "# ... (Include blocks for Missing Value, Uniqueness, Foreign Key, Numeric, Text analysis here if wanted) ...\n",
    "# print(\"\\n--- Finished Data Quality Checks ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading TARIFES data from: ../data/raw/TARIFES.csv\n",
      "TARIFES data loaded.\n",
      "Created Tariff Type lookup dictionary (using integer ID_TARIFA as key).\n"
     ]
    }
   ],
   "source": [
    "# --- Load and Process TARIFES Data for Lookup ---\n",
    "print(f\"\\nLoading TARIFES data from: {TARIFES_FILE}\")\n",
    "tariff_type_lookup = {} # Initialize empty\n",
    "try:\n",
    "    df_tarifes = pd.read_csv(TARIFES_FILE)\n",
    "    print(\"TARIFES data loaded.\")\n",
    "\n",
    "    # Create mapping functions directly here (simplified from notebook 03)\n",
    "    def map_tariff_type(code):\n",
    "        code_str = str(code) # Ensure it's a string for startswith etc.\n",
    "        if code_str in ['A', 'B', 'C', 'D']: return f\"Blue Zone {code_str}\"\n",
    "        if code_str == 'RES': return \"Resident\"\n",
    "        if code_str.startswith('GR'): return \"Green Zone\"\n",
    "        if code_str.startswith('BU'): return \"Bus Zone\"\n",
    "        if code_str.startswith('MA') or code_str.startswith('MB'): return \"Motorcycle\"\n",
    "        if code_str.startswith('ED'): return \"School/Special Zone\"\n",
    "        if code_str == 'CYD': return \"Loading/Unloading (DUM)\"\n",
    "        return \"Unknown\"\n",
    "\n",
    "    df_tarifes['TARIFA_TYPE'] = df_tarifes['CODI_TARIFA'].apply(map_tariff_type)\n",
    "\n",
    "    # Create lookup dict: ID_TARIFA (as int key) -> TARIFA_TYPE\n",
    "    # Ensure ID_TARIFA is treated as integer for lookup\n",
    "    tariff_type_lookup = df_tarifes.set_index('ID_TARIFA')['TARIFA_TYPE'].to_dict()\n",
    "    print(\"Created Tariff Type lookup dictionary (using integer ID_TARIFA as key).\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {TARIFES_FILE}. Tariff lookup will be empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading HORARIS data from: ../data/raw/HORARIS.csv\n",
      "HORARIS data loaded.\n",
      "Created Schedule Flags lookup dictionary (using integer ID_HORARI as key).\n"
     ]
    }
   ],
   "source": [
    "# --- Load and Process HORARIS Data for Lookup ---\n",
    "print(f\"\\nLoading HORARIS data from: {HORARIS_FILE}\")\n",
    "schedule_flags_lookup = {} # Initialize empty\n",
    "try:\n",
    "    df_horaris = pd.read_csv(HORARIS_FILE)\n",
    "    print(\"HORARIS data loaded.\")\n",
    "\n",
    "    # Create lookup dict: ID_HORARI (as int key) -> [APPLIES_ON_HOLIDAYS (bool), PARKING_ONLY_IN_SCHEDULE (bool)]\n",
    "    # Ensure index is integer\n",
    "    df_horaris_indexed = df_horaris.set_index('ID_HORARI')\n",
    "    schedule_flags_lookup = df_horaris_indexed[['INCLUS_FESTIUS', 'PARQUING_SOLS_DINS_HORARI']].astype(bool).T.to_dict('list')\n",
    "    \n",
    "    # Add handling for the invalid ID=0 if it exists\n",
    "    if 0 not in schedule_flags_lookup:\n",
    "         schedule_flags_lookup[0] = [None, None] # Assign None flags for ID 0\n",
    "         \n",
    "    print(\"Created Schedule Flags lookup dictionary (using integer ID_HORARI as key).\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {HORARIS_FILE}. Schedule lookup will be empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Geometry Construction (from Coordinates) ---\n",
      "Constructing LineString geometries...\n",
      "Invalid/problematic geometries found: 1 (includes 1 zero-length)\n",
      "Creating GeoDataFrame...\n",
      "GeoDataFrame created with 17274 valid geometries.\n"
     ]
    }
   ],
   "source": [
    "# --- Geometry Construction (from Coordinates) ---\n",
    "gdf_trams = None # Initialize to None\n",
    "if not df_trams.empty and all(col in df_trams.columns for col in ['LONGITUD_I', 'LATITUD_I', 'LONGITUD_F', 'LATITUD_F']):\n",
    "    print(\"\\n--- Geometry Construction (from Coordinates) ---\")\n",
    "\n",
    "    invalid_geom_count = 0\n",
    "    zero_length_count = 0\n",
    "    geometries = []\n",
    "    try:\n",
    "        print(\"Constructing LineString geometries...\")\n",
    "        \n",
    "        for index, row in df_trams.iterrows():\n",
    "            try:\n",
    "                # Check for NaN values before creating points\n",
    "                if pd.isna(row['LONGITUD_I']) or pd.isna(row['LATITUD_I']) or \\\n",
    "                   pd.isna(row['LONGITUD_F']) or pd.isna(row['LATITUD_F']):\n",
    "                   geometries.append(None)\n",
    "                   invalid_geom_count += 1 \n",
    "                   continue\n",
    "\n",
    "                point_start = Point(row['LONGITUD_I'], row['LATITUD_I'])\n",
    "                point_end = Point(row['LONGITUD_F'], row['LATITUD_F'])\n",
    "\n",
    "                if point_start.equals(point_end):\n",
    "                    zero_length_count += 1\n",
    "                    geometries.append(None) \n",
    "                    invalid_geom_count += 1\n",
    "                    continue\n",
    "                \n",
    "                line = LineString([point_start, point_end])\n",
    "                \n",
    "                if not line.is_valid:\n",
    "                    invalid_geom_count += 1\n",
    "                    geometries.append(None) \n",
    "                else:\n",
    "                    geometries.append(line)\n",
    "\n",
    "            except (GEOSException, ValueError) as e:\n",
    "                 print(f\"Error creating geometry for row index {index}, ID_TRAM {row.get('ID_TRAM', 'N/A')}: {e}\")\n",
    "                 invalid_geom_count += 1\n",
    "                 geometries.append(None)\n",
    "\n",
    "        print(f\"Invalid/problematic geometries found: {invalid_geom_count} (includes {zero_length_count} zero-length)\")\n",
    "\n",
    "        # --- Create GeoDataFrame ---\n",
    "        print(\"Creating GeoDataFrame...\")\n",
    "        # Use WGS84 (EPSG:4326) as CRS since coordinates are Lat/Lon\n",
    "        gdf_trams = gpd.GeoDataFrame(df_trams, geometry=geometries, crs=\"EPSG:4326\") \n",
    "        # Remove rows where geometry construction failed\n",
    "        gdf_trams = gdf_trams[gdf_trams.geometry.notna()].copy() # Use .copy() after filtering\n",
    "        print(f\"GeoDataFrame created with {len(gdf_trams)} valid geometries.\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"\\nError: GeoPandas or Shapely not installed. Cannot construct geometries.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during geometry processing: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping Geometry Construction: DataFrame empty or coordinate columns missing.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Mapping Tariff and Schedule Info onto gdf_trams ---\n",
      "Mapped TARIFA_TYPE using ID_TARIFA (as integer key).\n",
      "Mapped APPLIES_ON_HOLIDAYS and PARKING_ONLY_IN_SCHEDULE using ID_HORARIO1.\n",
      "\n",
      "--- Analysis of Mapped Data ---\n",
      "\n",
      "Final Distribution of Tariff Types:\n",
      "TARIFA_TYPE\n",
      "Motorcycle                 11643\n",
      "Loading/Unloading (DUM)     3095\n",
      "Blue Zone B                 1046\n",
      "Resident                     850\n",
      "Blue Zone A                  539\n",
      "Bus Zone                     100\n",
      "NaN                            1\n",
      "Name: count, dtype: int64\n",
      "Total Trams with missing/unmapped Tariff Type: 1\n",
      "\n",
      "Final Distribution of APPLIES_ON_HOLIDAYS:\n",
      "APPLIES_ON_HOLIDAYS\n",
      "False    17067\n",
      "True       206\n",
      "None         1\n",
      "Name: count, dtype: int64\n",
      "Total Trams with missing/unmapped Holiday Flag: 1\n",
      "\n",
      "Final Distribution of PARKING_ONLY_IN_SCHEDULE:\n",
      "PARKING_ONLY_IN_SCHEDULE\n",
      "False    16882\n",
      "True       391\n",
      "None         1\n",
      "Name: count, dtype: int64\n",
      "Total Trams with missing/unmapped Parking Only Flag: 1\n",
      "\n",
      "--- Enriched GeoDataFrame Head ---\n",
      "   ID_TRAM  ID_TARIFA  TARIFA_TYPE  ID_HORARIO1 APPLIES_ON_HOLIDAYS  \\\n",
      "0        7         46  Blue Zone A           82               False   \n",
      "1        8         52     Resident           76               False   \n",
      "2       13         46  Blue Zone A           81               False   \n",
      "3       14         46  Blue Zone A           81               False   \n",
      "4       19         54   Motorcycle           13               False   \n",
      "\n",
      "  PARKING_ONLY_IN_SCHEDULE                  ADREÇA  PLACES  \\\n",
      "0                    False    ROGER DE FLOR, 79, C       5   \n",
      "1                    False  LLUIS EL PIADOS, 9 , C      10   \n",
      "2                    False      MENDEZ NUÑEZ, 9, C       9   \n",
      "3                    False      MENDEZ NUÑEZ, 4, C       3   \n",
      "4                    False          ALI BEI, 42, C       8   \n",
      "\n",
      "                                          geometry  \n",
      "0  LINESTRING (2.17907 41.39384, 2.17893 41.39383)  \n",
      "1   LINESTRING (2.17853 41.39019, 2.1784 41.39038)  \n",
      "2  LINESTRING (2.17814 41.38934, 2.17795 41.38949)  \n",
      "3  LINESTRING (2.17829 41.38946, 2.17813 41.38957)  \n",
      "4   LINESTRING (2.1806 41.39341, 2.18049 41.39333)  \n",
      "\n",
      "Saving processed GeoDataFrame to: ../data/processed/trams_processed.gpkg\n",
      "Saved successfully.\n",
      "\n",
      "--- End of Notebook ---\n"
     ]
    }
   ],
   "source": [
    "# --- Merge/Map Tariff and Schedule Information ---\n",
    "\n",
    "# Check if gdf_trams was successfully created\n",
    "if gdf_trams is None or gdf_trams.empty:\n",
    "     print(\"\\nError: GeoDataFrame 'gdf_trams' is not available. Cannot perform mapping.\")\n",
    "elif 'tariff_type_lookup' not in locals() or not tariff_type_lookup:\n",
    "    print(\"\\nError: Tariff lookup dictionary not available. Cannot perform mapping.\")\n",
    "elif 'schedule_flags_lookup' not in locals() or not schedule_flags_lookup:\n",
    "     print(\"\\nError: Schedule flags lookup dictionary not available. Cannot perform mapping.\")\n",
    "else:\n",
    "    print(\"\\n--- Mapping Tariff and Schedule Info onto gdf_trams ---\")\n",
    "\n",
    "    # --- Map Tariff Type using ID_TARIFA (Ensure key type matches lookup dict) ---\n",
    "    try:\n",
    "        # Convert ID_TARIFA column to numeric first to match integer keys in lookup\n",
    "        tariff_keys_int = pd.to_numeric(gdf_trams['ID_TARIFA'], errors='coerce').astype('Int64') # Use nullable Int\n",
    "        gdf_trams['TARIFA_TYPE'] = tariff_keys_int.map(tariff_type_lookup)\n",
    "        print(\"Mapped TARIFA_TYPE using ID_TARIFA (as integer key).\")\n",
    "    except Exception as e:\n",
    "         print(f\"Error mapping TARIFA_TYPE: {e}. Check key types.\")\n",
    "         gdf_trams['TARIFA_TYPE'] = None # Assign None if mapping fails\n",
    "\n",
    "\n",
    "    # --- Map Schedule Flags using ID_HORARIO1 (Int) ---\n",
    "    try:\n",
    "        # Ensure ID_HORARIO1 is integer type for mapping\n",
    "        schedule_keys_int = gdf_trams['ID_HORARIO1'].astype(int) # Assume it can be cast directly\n",
    "        schedule_map_result = schedule_keys_int.map(schedule_flags_lookup)\n",
    "        \n",
    "        # Extract flags safely\n",
    "        gdf_trams['APPLIES_ON_HOLIDAYS'] = schedule_map_result.apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)\n",
    "        gdf_trams['PARKING_ONLY_IN_SCHEDULE'] = schedule_map_result.apply(lambda x: x[1] if isinstance(x, list) and len(x) > 1 else None)\n",
    "        print(\"Mapped APPLIES_ON_HOLIDAYS and PARKING_ONLY_IN_SCHEDULE using ID_HORARIO1.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error mapping schedule flags: {e}. Check key types and lookup.\")\n",
    "        gdf_trams['APPLIES_ON_HOLIDAYS'] = None\n",
    "        gdf_trams['PARKING_ONLY_IN_SCHEDULE'] = None\n",
    "\n",
    "\n",
    "    # --- Analyze Final Mapping Results ---\n",
    "    print(\"\\n--- Analysis of Mapped Data ---\")\n",
    "    if 'TARIFA_TYPE' in gdf_trams.columns:\n",
    "        print(\"\\nFinal Distribution of Tariff Types:\")\n",
    "        print(gdf_trams['TARIFA_TYPE'].value_counts(dropna=False)) \n",
    "        print(f\"Total Trams with missing/unmapped Tariff Type: {gdf_trams['TARIFA_TYPE'].isnull().sum()}\")\n",
    "    else:\n",
    "        print(\"\\nTARIFA_TYPE column not created.\")\n",
    "\n",
    "    if 'APPLIES_ON_HOLIDAYS' in gdf_trams.columns:\n",
    "        print(\"\\nFinal Distribution of APPLIES_ON_HOLIDAYS:\")\n",
    "        print(gdf_trams['APPLIES_ON_HOLIDAYS'].value_counts(dropna=False))\n",
    "        missing_hol_flag_count = gdf_trams['APPLIES_ON_HOLIDAYS'].isnull().sum()\n",
    "        print(f\"Total Trams with missing/unmapped Holiday Flag: {missing_hol_flag_count}\")\n",
    "    else:\n",
    "        print(\"\\nAPPLIES_ON_HOLIDAYS column not created.\")\n",
    "\n",
    "    if 'PARKING_ONLY_IN_SCHEDULE' in gdf_trams.columns:\n",
    "        print(\"\\nFinal Distribution of PARKING_ONLY_IN_SCHEDULE:\")\n",
    "        print(gdf_trams['PARKING_ONLY_IN_SCHEDULE'].value_counts(dropna=False))\n",
    "        missing_parkonly_flag_count = gdf_trams['PARKING_ONLY_IN_SCHEDULE'].isnull().sum()\n",
    "        print(f\"Total Trams with missing/unmapped Parking Only Flag: {missing_parkonly_flag_count}\")\n",
    "    else:\n",
    "         print(\"\\nPARKING_ONLY_IN_SCHEDULE column not created.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Enriched GeoDataFrame Head ---\")\n",
    "    # Display relevant columns\n",
    "    cols_to_show = ['ID_TRAM', 'ID_TARIFA', 'TARIFA_TYPE', 'ID_HORARIO1', 'APPLIES_ON_HOLIDAYS', 'PARKING_ONLY_IN_SCHEDULE', 'ADREÇA', 'PLACES', 'geometry']\n",
    "    # Ensure columns exist before selecting\n",
    "    cols_to_show = [col for col in cols_to_show if col in gdf_trams.columns]\n",
    "    print(gdf_trams[cols_to_show].head())\n",
    "\n",
    "    # --- Save Processed Data ---\n",
    "    OUTPUT_DIR = \"../data/processed\" \n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    OUTPUT_FILE = os.path.join(OUTPUT_DIR, \"trams_processed.gpkg\") # GeoPackage format\n",
    "\n",
    "    try:\n",
    "        print(f\"\\nSaving processed GeoDataFrame to: {OUTPUT_FILE}\")\n",
    "        gdf_trams.to_file(OUTPUT_FILE, driver=\"GPKG\", layer=\"trams\")\n",
    "        print(\"Saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving GeoDataFrame: {e}\")\n",
    "print(\"\\n--- End of Notebook ---\") # Added end marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving processed GeoDataFrame to: ../data/processed/trams_processed.gpkg\n",
      "Saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Save Processed Data ---\n",
    "import os \n",
    "\n",
    "# Ensure gdf_trams exists and is not empty before saving\n",
    "if 'gdf_trams' in locals() and not gdf_trams.empty:\n",
    "    OUTPUT_DIR = \"../data/processed\" \n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    OUTPUT_FILE = os.path.join(OUTPUT_DIR, \"trams_processed.gpkg\") # GeoPackage format\n",
    "\n",
    "    try:\n",
    "        print(f\"\\nSaving processed GeoDataFrame to: {OUTPUT_FILE}\")\n",
    "        # Ensure all column types are supported by GeoPackage driver before saving\n",
    "        # Object columns can sometimes cause issues, check/convert if needed\n",
    "        # Example: gdf_trams['some_object_column'] = gdf_trams['some_object_column'].astype(str)\n",
    "        gdf_trams.to_file(OUTPUT_FILE, driver=\"GPKG\", layer=\"trams\")\n",
    "        print(\"Saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving GeoDataFrame: {e}\")\n",
    "        print(\"You might need to check column data types for GeoPackage compatibility (e.g., convert object columns to string).\")\n",
    "else:\n",
    "    print(\"\\nSkipping save: gdf_trams GeoDataFrame not found or is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
