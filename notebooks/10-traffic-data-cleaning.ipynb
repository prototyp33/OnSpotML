{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# Traffic Data Cleaning Pipeline\n",
    "\n",
    "This notebook loads the processed traffic data, applies cleaning steps \n",
    "identified during the quality audit (primarily handling missing values),\n",
    "and saves the cleaned dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "INPUT_FILE = \"../data/processed/traffic_history_2022_2023_processed.parquet\"\n",
    "OUTPUT_DIR = \"../data/cleaned\" # Save cleaned data to a new directory\n",
    "OUTPUT_FILENAME = \"traffic_history_2022_2023_cleaned.parquet\"\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_DIR, OUTPUT_FILENAME)\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ../data/processed/traffic_history_2022_2023_processed.parquet\n",
      "Data loaded in 1.78 seconds.\n",
      "Original shape: (106964597, 4)\n",
      "\n",
      "Missing values before cleaning:\n",
      "ID_TRAM               0\n",
      "Timestamp             0\n",
      "EstatActual       12221\n",
      "PrevisioActual    12221\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "print(f\"Loading data from: {INPUT_FILE}\")\n",
    "start_load_time = time.time()\n",
    "df = pd.read_parquet(INPUT_FILE)\n",
    "end_load_time = time.time()\n",
    "print(f\"Data loaded in {end_load_time - start_load_time:.2f} seconds.\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(\"\\nMissing values before cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling missing values using forward fill within each ID_TRAM group...\n",
      "\n",
      "Missing values after forward fill:\n",
      "EstatActual       532\n",
      "PrevisioActual    532\n",
      "dtype: int64\n",
      "\n",
      "Handling remaining NaNs (likely first entries for some segments)...\n",
      "\n",
      "Missing values after second pass (backward fill):\n",
      "EstatActual       0\n",
      "PrevisioActual    0\n",
      "dtype: int64\n",
      "Missing value handling done in 13.68 seconds.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Handle Missing Values ---\n",
    "# Strategy: Forward fill within each segment group. \n",
    "# This assumes the status persists until a new reading is available.\n",
    "# It handles the small number of missing values (0.011%) without complex imputation.\n",
    "\n",
    "print(\"\\nHandling missing values using forward fill within each ID_TRAM group...\")\n",
    "start_ffill_time = time.time()\n",
    "\n",
    "# Sort ensures forward fill works correctly within each group's timeline\n",
    "df.sort_values(by=['ID_TRAM', 'Timestamp'], inplace=True)\n",
    "\n",
    "# Apply forward fill within each group\n",
    "df['EstatActual'] = df.groupby('ID_TRAM')['EstatActual'].ffill()\n",
    "df['PrevisioActual'] = df.groupby('ID_TRAM')['PrevisioActual'].ffill()\n",
    "\n",
    "# Check for any remaining NaNs (could happen if the *first* record for a segment is NaN)\n",
    "remaining_na = df[['EstatActual', 'PrevisioActual']].isnull().sum()\n",
    "print(\"\\nMissing values after forward fill:\")\n",
    "print(remaining_na)\n",
    "\n",
    "if remaining_na.sum() > 0:\n",
    "    print(\"\\nHandling remaining NaNs (likely first entries for some segments)...\")\n",
    "    # Option 1: Fill with a default value (e.g., 0 for 'No Data' or median/mode)\n",
    "    # df['EstatActual'].fillna(0, inplace=True) \n",
    "    # df['PrevisioActual'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Option 2: Backward fill (fills first entries from the next valid one in group)\n",
    "    df['EstatActual'] = df.groupby('ID_TRAM')['EstatActual'].bfill()\n",
    "    df['PrevisioActual'] = df.groupby('ID_TRAM')['PrevisioActual'].bfill()\n",
    "    \n",
    "    # Option 3: Drop rows with remaining NaNs (if acceptable)\n",
    "    # df.dropna(subset=['EstatActual', 'PrevisioActual'], inplace=True)\n",
    "    \n",
    "    print(\"\\nMissing values after second pass (backward fill):\")\n",
    "    print(df[['EstatActual', 'PrevisioActual']].isnull().sum())\n",
    "    \n",
    "    # Final check - drop any rows if bfill didn't work (segment entirely NaN?)\n",
    "    df.dropna(subset=['EstatActual', 'PrevisioActual'], inplace=True)\n",
    "\n",
    "\n",
    "end_ffill_time = time.time()\n",
    "print(f\"Missing value handling done in {end_ffill_time - start_ffill_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Data Check ---\n",
      "Cleaned shape: (106964597, 4)\n",
      "\n",
      "Missing values after all cleaning:\n",
      "ID_TRAM           0\n",
      "Timestamp         0\n",
      "EstatActual       0\n",
      "PrevisioActual    0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "ID_TRAM                    int64\n",
      "Timestamp         datetime64[ns]\n",
      "EstatActual                 Int8\n",
      "PrevisioActual              Int8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Final Data Check ---\n",
    "print(\"\\n--- Final Data Check ---\")\n",
    "print(f\"Cleaned shape: {df.shape}\")\n",
    "print(\"\\nMissing values after all cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes) # Check if ffill changed dtypes (should be fine with Int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving cleaned data to: ../data/cleaned/traffic_history_2022_2023_cleaned.parquet\n",
      "Cleaned data saved successfully in 3.19 seconds.\n",
      "\n",
      "--- Data Cleaning Complete ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4. Save Cleaned Data ---\n",
    "print(f\"\\nSaving cleaned data to: {OUTPUT_FILE}\")\n",
    "start_save_time = time.time()\n",
    "try:\n",
    "    df.to_parquet(OUTPUT_FILE, index=False, engine='pyarrow')\n",
    "    end_save_time = time.time()\n",
    "    print(f\"Cleaned data saved successfully in {end_save_time - start_save_time:.2f} seconds.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR saving cleaned data: {e}\")\n",
    "\n",
    "print(\"\\n--- Data Cleaning Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
